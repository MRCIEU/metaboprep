---
title: "Metabolomics QC Report"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    number_sections: true
    toc: false
    toc_depth: 2
space_betwee_paragraphs: true
fig_caption: true
always_allow_html: yes
link-citations: true
params: 
 Rdatafile: NA
 out_dir: out_dir
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r args_2_variables, include = FALSE, warning=FALSE, message=FALSE, error=FALSE}
library(MetaboQC)
library(tidyverse)

###########################
# Read in R object with Rdata 
## file passed as a paramater
###########################
## necessary arguments
## 1) not QC'd metabolite
## 2) sample data
## 3) feature data
## 4) QC'd metabolite data
## 5) data/out directory path
## 6) project
## 7) platform

#n = paste0(data_dir, "MetaboQC_release_", today, "/ReportData.Rdata")
load(params$Rdatafile)
out_dir = params$out_dir

```

```{r data_2_tibble, include = FALSE, quote=F, comment=NA, warning=FALSE, message=FALSE, error=FALSE }

## turn data into tibbles
#metdata = cbind(rownames(metdata), metdata); colnames(metdata)[1] = "SamID"
metdata = tibble::as_tibble(metdata)
##
sdata = cbind(rownames(sdata), sdata); colnames(sdata)[1] = "SamID"
sdata = tibble::as_tibble(sdata)
##
fdata = cbind(rownames(fdata), fdata); colnames(fdata)[1] = "FeatureID"
fdata = tibble::as_tibble(fdata)
##
#qdata = cbind(rownames(qdata), qdata); colnames(qdata)[1] = "SamID"
qdata = tibble::as_tibble(qdata)

varexp = varexp[,1]
```

<!---The <style> code below centers the title and date and justifys all paragraph text --->
<style type="text/css">
h1.title {
  font-size: 38px;
  text-align: center;
}
h4.author { /* Header 4 - and the author and data headers use this too  */
    font-size: 18px;
  text-align: center;
}
h4.date { /* Header 4 - and the author and data headers use this too  */
  font-size: 18px;
  text-align: center;
}
body {
text-align: justify
}
</style>
<!--- --->

Report relates to:

  * Project: `r project`  
  * Platform: `r platform`

The `MetaboQC` `R` package performs two operations: it provides an assessment of the raw metabolomics data and then performs quality control on this data. This report provides descriptive information for raw and quality controlled metabolomics data for the project `r project`. The quality control pipeline is as follows (in order):

```{r QC-pipeline-flowdiagram, echo=FALSE, out.width='100%'}
#knitr::include_graphics("")
```

1.
2.
3.
4.
5.

Issues can be raised on [GitHub](https://github.com/MRCIEU/MetaboQC/issues). Questions relating to the `MetaboQC` pipeline can be directed to [David Hughes](mailto:d.a.hughes@bristol.ac.uk).

`MetaboQC` is published in [Wellcome Open Research]() and can be cited as:

> `MetaboQC`: an `R` package for metabolomics quality control across analytical platforms.......................

***

\pagebreak

# Raw data
  
## N  
  * Number of samples in data = `r nrow(metdata)`  
  * Number of features in data = `r ncol(metdata)`  

## Power
**Exploration for case/control and continuous outcome data:**

Analytical power analysis for both case/control (50%/50%) and continuous variable analysis. Estimated power is given for the max sample size (N) and smaller N's in the instance of variabitiy in missingness among features. The case control power analysis assumes that cases and controls are split evenly in your dataset, and the N on the x-axis is the total N. 

```{r power_exploration, echo=F, quote=F, comment=NA, fig.width=8, fig.height=5, warning=FALSE, message=FALSE, error=FALSE }
####################################   
# Run power analysis and generate plot
####################################
( run.power.make.plot(mydata = metdata ) )

```

## Missingness
Missingness is evaluated across samples and features using the original/raw scaled data set. 

### Summary of missingness 
Figures give the sample and feature missingness distributions. The median point estimates are indicated by the red vertical line. 

The table gives an estimate of the proportion of missingness for quintiles of the sample and feature missingness data distribution. 

```{r run.missingness, echo = FALSE, fig.width = 10, fig.height = 3.5, warning=FALSE, message=FALSE, error=FALSE}
mis = missingness.sum(mydata = metdata)

## print missingness table
gridExtra::grid.arrange( gridExtra::arrangeGrob ( mis[[4]][[1]] , 
                                                  mis[[4]][[2]] , 
                                                  mis[[4]][[3]] ,
                                                  ncol = 3, 
                                                  top = "-- Estimates of missingness for samples and features --") )
 

```
  
    
### Feature missingnes: sample size
Given the study sample size, the table below provides the sample size for features at various levels of missingness.

```{r samplesize.withmissingness, echo = FALSE, fig.width = 5, fig.height = 2.5, warning=FALSE, message=FALSE, error=FALSE}
mis[[4]][[4]]
```

### Feature missingness: influenced by possible explanatory variables 
Feature missingness may be influenced by the metabolites|features biology or pathway calssification, or the mass spec methodology. The figure provides an illustrative evaluation of the proportion of *feature missigness* as a product of the variable(s) available in the raw data files. 

```{r featurebatchvariables, echo = FALSE, warning=FALSE, message=FALSE, error=FALSE}
## possible batch variables that have been observed in 
## METABOLON and NIGHTINGALE sample-annotation-batch-data
possible_batch_variables = c("SUPER_PATHWAY","PLATFORM", "class", "subclass")

## matching variables
w = which(possible_batch_variables %in% colnames(fdata))
matched_variables = possible_batch_variables[w]

## batch variables, that are variable in the sample
w = which( apply(fdata[,matched_variables], 2, function(x){length(table(x))}) > 1 )
class_variables = matched_variables[w]

```

```{r featuremissingnessPLOT,  echo=F, fig.width = 12, fig.height = 8, warning=FALSE, message=FALSE, error=FALSE}
## MISSINGNESS
###################################
## Iterate over each batch variable
###################################
ClassMisPlots = lapply( class_variables , function(x){
  out = variable.by.factor( dep = fdata$feature_missingness , 
                           indep = unlist( fdata[,x] ), 
                           dep_name = "feature missingness", 
                           indep_name = x, orderfactor = TRUE, violin = FALSE )
  return(out)
  })


## plot the output
gridExtra::grid.arrange( grobs = ClassMisPlots, ncol = 1)

```

### Sample missingness: batch effects/variables

#### Univariate evaluation: batch effects
The figure provides an illustrative evaluation of the proportion of *sample missigness* as a product of sample batch variables provided by your supplier. This is the univariate influence of batch effects on *sample missingness*.
   
```{r samplebatchvariables, echo = FALSE, warning=FALSE, message=FALSE, error=FALSE}
## possible batch variables that have been observed in 
## METABOLON and NIGHTINGALE sample-annotation-batch-data
possible_batch_variables = c("BOX_ID","BOX_WELL","RUN_DAY", 
                             "Internal_Box_ID", "Sample_Type", 
                             "NMR_Spectrometer", "Sample_prep_date_time",
                             "Buffer_ID", 
                             "ControlB_TMSP_LMWM_Linewidth_at_half_height_(0.3Hz_line_broadening)")

## matching variables
w = which( possible_batch_variables  %in%  colnames(sdata)  )
if( length(w) > 0 ){
  matched_variables = possible_batch_variables[w]
  
  ## batch variables, that are variable in the sample
  w = which( apply( sdata[,matched_variables], 2, function(x){ length( table(x) ) } ) > 1 )
  batch_variables = matched_variables[w]
} else {
  batch_variables = NA
}

## In case all batch variables are not variable (typically because sample size is small and all done in 1 go.)
if(length(batch_variables) == 0){ batch_variables = NA }

```

```{r Sam_missingnessPLOT,  echo=F, fig.width = 15, fig.height = 15, warning=FALSE, message=FALSE, error=FALSE}
## MISSINGNESS
###################################
## Iterate over each batch variable
###################################
if( !is.na(batch_variables[1]) ) {
  BatchMisPlots = lapply( batch_variables , function(x){
    out = variable.by.factor( dep = sdata$sample_missingness , 
                              indep = unlist( sdata[,x] ), 
                              dep_name = "sample missingness", 
                              orderfactor = FALSE, 
                              indep_name = x, violin = TRUE)
    return(out)
  })
  
  
  ## plot the output
  gridExtra::grid.arrange( grobs = BatchMisPlots, ncol = 1)
  
} else {
  paste0(" -- No sample level batch variables were provided or all were invariable -- ")
}

```

#### Multivariate evaluation: batch variables
TypeII ANOVA: the eta-squared (eta-sq) estimates are an estimation on the proportion of variation explained by each independent variable, after accounting for all other variables, as derived from the sum of squares. This is a multivariate evaluation of batch variables on *sample missingness*.

```{r sample_missingness_multivatiaveANOVA, echo = FALSE, fig.width = 9, fig.height = 2, warning=FALSE, message=FALSE, error=FALSE}
if( !is.na(batch_variables[1]) ) {
  ( multivariate.anova(dep = sdata$sample_missingness, indep_df = sdata[ ,batch_variables ] ) )
} else {
  paste0(" -- No sample level batch variables were provided or all were invariable -- ")
  }
```

## Sample Total Peak Area (TPA):
Total peak area (TPA) is simply the sum of the abundances measured across all features. TPA is one measure that can be used to identify unusual samples given their entire profile. However, the level of missingness in a sample may influence TPA. To account for this we:  

1. Evaluate the correlation between TPA estimates across all features with TPA measured using only those features with complete data (no missingness).  
2. Evaluate the relationship between sample missingness on TPA, using only complete feature data. 
    * Note: it is expected, and has been observed, that TPA using all features (not accounting for missingness) will exhibit a stronger relationship with sample missingness, but that is not explicitly evaluated here.

3. Determine if the batch effects have a measurable impact on TPA.

### Corrleation
Correlation between total peak area (at complete features) and missingness

```{r, echo=F, fig.width = 7, fig.height = 5, warning=FALSE, message=FALSE, error=FALSE}
a = cor.test( sdata$sample_missingness, sdata$TPA_completefeature)
###
( 
  tpamis = sdata %>% ggplot( aes(x = TPA_completefeature, y = sample_missingness)) +
  geom_point( fill = "grey", alpha = 0.8, size = 1.5) + 
  geom_smooth(method = "loess", color = "red", size = 2)  +
  geom_smooth(method = "lm", color = "blue", size = 2)  +
  labs(x = "TPA, complete features", y = "sample missingness",
       title = paste0( "TPA as influenced by missingness \nSpearmans's cor = ", round(a$estimate, d = 4), " p-value = ", 
                    formatC( a$p.value, format = "e", digits = 2) ))
  )

```

### Univariate evaluation: batch effects
The figure below provides an illustrative evaluation of the  *total peak area* as a product of sample batch variables provided by your supplier. 

```{r TPAsummary, echo = FALSE, fig.width = 12, fig.height = 10,  warning=FALSE, message=FALSE, error=FALSE}

if( !is.na(batch_variables[1]) ) {
  BatchMisPlots = lapply( batch_variables , function(x){
    out = variable.by.factor( dep = sdata$TPA_completefeature, 
                              indep = unlist( sdata[,x] ), 
                              dep_name = "total peak area", 
                              orderfactor = FALSE, 
                              indep_name = x, violin = TRUE)
    return(out)
  })
  
  ## plot the output
  gridExtra::grid.arrange( grobs = BatchMisPlots, ncol = 1)
  
} else {
  paste0(" -- No sample level batch variables were provided or all were invariable -- ")
}

```

### Multivariate evaluation: batch variables
TypeII ANOVA: the eta-squared (eta-sq) estimates are an estimation on thÃ§e proportion of variation explained by each independent variable, after accounting for all other variables, as derived from the sum of squares. This is a multivariate evaluation of batch variables on *TPA*.

```{r sample_tpa_multivatiaveANOVA, echo = FALSE, fig.width = 9, fig.height = 2, warnings = FALSE, message=FALSE, error=FALSE}
if( !is.na(batch_variables[1]) ) {
  ( multivariate.anova(dep = sdata$TPA_completefeature, 
                                indep_df = sdata[,batch_variables ] ) ) 
}else {
  paste0(" -- No sample level batch variables were provided or all were invariable -- ")
  }
```

## Feature Distributions

### Normality
**How many feature distributions may be considered normal distributions?**

```{r ,echo=F, warning=FALSE, message=FALSE, error=FALSE}
wstat = apply(metdata, 2, function(x){
  x = na.omit( unlist(x) )
  if(length(x)> 5000){ x = sample(x, 5000)}
  if( ( var(x) != 0 & length(x) >= 40 ) == TRUE ){
      out = shapiro.test(unlist(x))$statistic  
  } else {
    out = NA  
    }
  return(out)
  })

## how many stats were estimated
count = length(wstat)
nacount = sum(is.na(wstat))
remain_count = count - nacount
# wstat = na.omit(wstat)
normalcount = sum(wstat >= 0.9, na.rm = TRUE)

```

Of the `r count` features in the data `r nacount` features were excluded from this analysis because of no variation or to few observations (n < 40). Of the remaining `r remain_count` metabolite features, a total of `r normalcount` may be considered normally distributed given a Shapiro W-statstic >= 0.9.
 
### W-stat and log transform
**W-stat distributions and does loging your data always improve the W-stat?**

A W-statistic value of 1 indicates the sample distribution is perfectly normal and value of 0 indicates it is perfectly uniform. Log transformation of data *may not* improve its normality.

```{r shpiroW, echo = FALSE, fig.width = 10, fig.height = 4, warning=FALSE, message=FALSE, error=FALSE}
W = wstat
pcol = RColorBrewer::brewer.pal(9, "Set1")
###
W_log10 = apply(metdata, 2, function(x){
  x = na.omit( unlist(x) )
  x = log10(x+1)
  if(length(x) > 5000){ x = sample(x, 5000) }
  if( ( var(x) != 0 & length(x) >= 40 ) == TRUE ){
      out = shapiro.test(unlist(x))$statistic  
  } else {
    out = NA  
    }
  return(out)
  })

## Plot
par(mfrow = c(1,2), oma = c(2,1,1,1))
hist(W, col = pcol[2], 
     main = paste("Distribution of W statistics on\nRaw Metabolite Abundances"), 
     xlab = "W", 
     ylab = "Frequency",
     cex.main = 0.75)
abline(v = 0.95, col = pcol[1])
normcount = sum(W >= 0.95)
##
mtext( paste0(normcount,
              " of the metabolites exhibit distributions\nthat may declared normal, given a W-stat >= 0.95"), 
       cex = 0.75, side = 1, outer = TRUE, line = 0, adj = 0.1, col = pcol[2])
  ### LOG
LogMakesDistributionWorse = c( sum( W_log10 < W , na.rm = TRUE), signif( sum( W_log10 < W , na.rm = TRUE)/length(!is.na(W) ), d = 3)*100)
  ##
hist(W_log10, col = pcol[3], 
     main = paste("Distribution of W statistics on\nlog10 Metabolite Abundances"), 
     xlab = "W", 
     ylab = "Frequency",
     cex.main = 0.75)
mtext( paste0("In ", LogMakesDistributionWorse[1],
              " instances or ", LogMakesDistributionWorse[2], "% of the tested metabolites\nthe log10 data W-stat is < raw data W-stat."), cex = 0.75, side = 1, outer = TRUE, line = 0, adj = 0.9, col = pcol[3])

```

### Distributions
A pdf report is being written to `r paste0( out_dir, project, "_outlier_detection_pre_filtering.pdf")` that contains dotplot, histogram and distribution summary statistics for each metabolite in your data set, providing an opportunity to visially inspect all your metabolites feature data distributions.

## Outliers
**Evaluation of the number of samples and features that are outliers across the data.**

The table reports the number of point estimates for the minimum (0%), median (50%), and maximum (100%) number of outlying features across samples and outlying samples across features. 

```{r, echo = FALSE, fig.width = 6, fig.height = 2.5, warning=FALSE, message=FALSE, error=FALSE}
today = Sys.Date()
today = gsub("-","_",today)
  
  
outlier_filename <- paste0( out_dir, project, "_outlier_detection_pre_filtering.pdf")

## feauture outlier summary
outlier_summary = outlier.summary(dtst = metdata, 
                           pdf_filename = outlier_filename, 
                           nsd = 5)
```

```{r, echo = FALSE, fig.width = 6, fig.height = 2.5, warning=FALSE, message=FALSE, error=FALSE}
outlier_summary[[2]]
```

## Feature correlation structure

### Correlation structure among features
The figure shows a clustering dendrogram of feature correlation. The horizontal line represents a Spearman's rho of approximately 0.75.

```{r featuredendrogram, echo = FALSE, fig.width = 15, fig.height = 6,  warning=FALSE, message=FALSE, error=FALSE}
######
tree = as.dendrogram( ftree )
## plot paramaters
nodePar <- list(lab.cex = 0.6, pch = c(NA, 19), 
                cex = 0.7, col = "cornflowerblue")
## PLOT
plot(tree, nodePar = nodePar, leaflab = "none", edgePar = list(col = c("grey30","grey80"), lwd = 2:1) )
#rect.hclust( Stree[[1]] , h = 0.20, border="skyblue")
abline(h = 0.4, col = "coral2", lwd = 2)
```

### Independent features
We estimate, based on clustering analysis, that there are a total of `r sum(fdata$independent_features_binary)` independent features in your metabolite data set. This is given a Spearman's rho of approximately 0.75, among the `r sum( !is.na(fdata$k) )` features with data for at least 20% of samples (<= 80% missingness allowed in correlation analysis). 

**Note**: A total of `r sum(table(fdata$k) == 1)` features correlated with NO other features at a Spearman's rho > 0.75, and are strictly independent. There were only `r sum(table(fdata$k) > 1)` clusters of features consisting of two or more features. The largest cluster consists of `r max(table(fdata$k))` features.


## Sample correlation structure

### Correaltion structure among samples
The scree plot (left) gives the number of principal components (PCs) and the sample variance explained by each PC. The PC plot (right) shows the top two PCs explaining the largest proportion of sample variance.

```{r PCA_1, echo = FALSE, fig.width = 10, fig.height = 5 , warning=FALSE, message=FALSE, error=FALSE }
pcol = RColorBrewer::brewer.pal(9, "Set1")

x = paste0("PC", 1:10)
mypca = as.data.frame( sdata[, x] )
#varexp = read.table( paste0(data_dir,"pc_varexp.txt" ) , h = T)[,1]
if(length(varexp) > 40){
  varexp = varexp[1:40]
  }

## how many significant PCs are there ???
sigpcs = length( grep("_outlier", colnames(sdata)) )/3
## how many outliers are there ?
w = grep("_3_SD_outlier",  colnames(sdata))
sdata$PCA_outliers = apply(sdata[,w], 1, sum)
sdata$PCA_outliers[ sdata$PCA_outliers > 1 ] = 1

##
cuttoff = sapply(3:5, function(sd){
  out = sapply(1:sigpcs, function(x){
    o = outliers( unlist(mypca[,x]), sd)[[3]] 
    return(o)
  })
  return(out)
  })
rownames(cuttoff) = paste0("PC", 1:nrow(cuttoff))
colnames(cuttoff) = paste0("sd", 1:ncol(cuttoff)+2)


################################
##  PLOTTING
################################
### complete feature count
indfcount = sum( fdata$independent_features_binary == 1)
  
#####  
par(mfrow  = c(1, 2) )
plot(varexp, pch = 21, cex = 1.5, bg = pcol[1], type = "b",
      main = "Variance Explained by each PC", 
      xlab = "PC", ylab = "variance explained")
######
ppcol = rep(pcol[2], nrow(mypca)); ppcol[which(sdata$PC1_3_SD_outlier == 1 | sdata$PC2_3_SD_outlier == 1)] = pcol[3]
#####
plot(mypca[,1], mypca[,2], pch = 21, bg = ppcol, main = "PCA w/outliers at 3SD",
     sub = paste0("a total of ", indfcount, " independent features used to construct the pca"), 
     cex.sub = 0.7, cex = 1.5, 
     xlab = paste0("PC1, VarExp = ", signif(varexp[1], d = 3 )*100, "%"),
     ylab = paste0("PC2, VarExp = ", signif(varexp[2], d = 3 )*100, "%"))
## pc1 outliers
cutcol = c("grey","orange","red")
for(i in 1:3){
  abline(v = cuttoff[1, i], col = cutcol[i])
  abline(v = -cuttoff[1, i], col = cutcol[i])
  ###
  abline(h = cuttoff[2, i], col = cutcol[i])
  abline(h = -cuttoff[2, i], col = cutcol[i])
  }



```

1. The PC plot includes exclusion lines at 5SD (red), 4SD (orange), and 3SD (grey) from the mean.

2. Missing data was imputed to median estimates of that feature to retain as many features as possible.

3. Given the observations from the principle component analysis:
    * a total of `r sigpcs` PCs have been declared significant given the estimated acceleration factor (min = 2, for any analysis).
    * a total of `r sum( c( sdata$PCA_outliers ) )` individuals are flagged for possible exclusion from further analysis, given a standard deviation cuttoff of 3SD of the mean. An exclusion (0|1, 1 = exclude) variable "PCA_outliers" is available in your sample annotation file.

### Top 5 PCs

A matrix plot of the top 5 PCS, unless the PC acceleration factor estimated for your data set exceeds 5 then the number of PCs plotted will equal the acceleration factor (max = 10). Included in the plot are the 3rd (grey), 4th (orange), and 5th (red) SD from the mean, which are each possible cuttoffs for outlier filtering. 

```{r PCApairsplot, echo = FALSE, fig.width = 12, fig.height = 12, warning=FALSE, message=FALSE, error=FALSE}

## PCA Pairs Plot
x = 1:sigpcs
if(x[1] < 5){x = 5}
pcapairs_bymoose( mypca[, 1:x ], varexp)


```

***

\pagebreak

# QC data

## N 
  * Number of samples in data = `r nrow(qdata)`  
  * Number of features in data = `r ncol(qdata)`  

## Relative to the raw data
  * `r nrow(metdata) - nrow(qdata)` samples were QC'd out, given the user's criteria.
  * `r ncol(metdata) - ncol(qdata)` features were QC'd out, given the user's criteria.
  * Please review your log file for the number of features and samples excluded and why. 
  
## Notes
### Outlying samples at each metabolite|feature

There may be extreme outlying observations at individual metabolites|features that have not been accounted for. You may want to:

1. turn these observations into NAs
2. windsorize the data to some maximum value
3. rank normalize the data which will place those outliers into the top of the ranked standard normal distribution
4. turn these observations into NAs and then impute them along with other missing data in your data set. 


```{r, echo = FALSE, fig.width = 12, fig.height = 10 }

## III QC'd data set 

### VIIIa. structure among samples : PCA


# ## extract names of independent features
# w = which(fdata$independent_features_binary == 1)
# indf = fdata$FeatureID[w]
# ##
# qcd_PCs_outliers = pc.and.outliers(metabolitedata = qdata, 
#                                  indfeature_names = indf)
# ##
# varexp = qcd_PCs_outliers[[2]][1:5]
# ##
# pcapairs_bymoose( qcd_PCs_outliers[[1]][,1:5], varexp)

```





